import pydra
from pathlib import Path
import nest_asyncio
import time
from shutil import copyfile
import json
import os
import glob

import attr
from nipype.interfaces.base import (
    Directory,
    File,
)
from pydra import ShellCommandTask
from pydra.engine.specs import SpecInfo, ShellSpec

from registration import BRAINSResample
from segmentation.specialized import BRAINSConstellationDetector

@pydra.mark.task
def get_subject(subject_list):
    return subject_list

@pydra.mark.task
def append_filename(filename="", append_str="", extension="", directory=""):
    new_filename = f"{Path(Path(directory) / Path(Path(filename).with_suffix('').with_suffix('').name))}{append_str}{extension}"
    return new_filename 

@pydra.mark.task
def copy_from_cache(cache_path, output_dir):
    copyfile(cache_path, Path(output_dir) / Path(cache_path).name)

if __name__ == "__main__":
    nest_asyncio.apply()
    # Set the location of the cache and clear its contents before running 
    output_dir = "/localscratch/Users/cjohnson30/output_dir"
    cache_dir = "/localscratch/Users/cjohnson30/cache_dir"
    os.system(f'rm -rf {cache_dir}/*') # Only deleting cache now as the pipeline is being developed and tested
 
    # Get the subject data listed in the subject_jsons.json file 
    subject_t1s = []
    with open('/localscratch/Users/cjohnson30/BRAINSPydra/subject_jsons.json') as json_file:
        data = json.load(json_file)
        for subject in data:
            subject_t1s.append(data[subject]["t1"])
    
    source_node = pydra.Workflow(name="source_node", input_spec=["t1"],)
    source_node.split("t1")
    source_node.inputs.t1 = subject_t1s
    
#    source_node.add(get_subject(name="get_subject", subject_list=source_node.lzin.subject_list))
#    source_node.set_output([("t1", source_node.get_subject.lzout.out)])
#
#    with pydra.Submitter(plugin="cf") as sub:
#        sub(source_node)
#    result = source_node.result() 
#    print(result)
#    # Before workflow, source node - takes in all subjects as list and outputs an iterable (1 subject information) - attached to the input spec of workflow
#    # output_spec should be connected to a sink node
#    # source node: absolute terms -  an outer workflow interfaces with sink and source nodes, source and sink should be generic and reusable
## everything between source and sink are generic and do not interact with real world - that is the job of source and sink
#    # workflow virtual files
#    # sink takes from virtual to absolute
#    # Decouple reference files, but they have different locations but I ask for the directory
#
#    # Define the workflow
    wf = pydra.Workflow(name="wf",input_spec=["t1"], t1=source_node.lzin.t1, cache_dir=cache_dir)
#    #                              output_spec # outputs from the set_output, autogenerated paths of cache)
#    wf.add(source_node)
#
#    # Set the filenames of the outputs of BCD
    wf.add(append_filename(name="outputLandmarksInInputSpace",       filename=wf.lzin.t1, append_str="_BCD_Original",                extension=".fcsv"))
#    wf.add(append_filename(name="outputResampledVolume",             filename=wf.source_node.lzout.t1, append_str="_BCD_ACPC",                    extension=".nii.gz"))
#    wf.add(append_filename(name="outputTransform",                   filename=wf.source_node.lzout.t1, append_str="_BCD_Original2ACPC_transform", extension=".h5"))
#    wf.add(append_filename(name="outputLandmarksInACPCAlignedSpace", filename=wf.source_node.lzout.t1, append_str="_BCD_ACPC_Landmarks",          extension=".fcsv"))
#    wf.add(append_filename(name="writeBranded2DImage",               filename=wf.source_node.lzout.t1, append_str="_BCD_Branded2DQCimage",        extension=".png"))
#
#    # Set the inputs of BCD
#    bcd = BRAINSConstellationDetector("BRAINSConstellationDetector").get_task()
#    bcd.inputs.inputVolume =                       wf.source_node.lzout.t1
#    bcd.inputs.inputTemplateModel =                "/Shared/sinapse/CACHE/20200915_PREDICTHD_base_CACHE/Atlas/20141004_BCD/T1_50Lmks.mdl"
#    bcd.inputs.LLSModel =                          "/Shared/sinapse/CACHE/20200915_PREDICTHD_base_CACHE/Atlas/20141004_BCD/LLSModel_50Lmks.h5"                 # can be in config file, hardcoded
#    bcd.inputs.atlasLandmarkWeights =              "/Shared/sinapse/CACHE/20200915_PREDICTHD_base_CACHE/Atlas/20141004_BCD/template_weights_50Lmks.wts" # hardcoded
#    bcd.inputs.atlasLandmarks =                    "/Shared/sinapse/CACHE/20200915_PREDICTHD_base_CACHE/Atlas/20141004_BCD/template_landmarks_50Lmks.fcsv"
#    bcd.inputs.houghEyeDetectorMode =              1
#    bcd.inputs.acLowerBound =                      80.000000
#    bcd.inputs.interpolationMode =                 "Linear"
#    bcd.inputs.outputLandmarksInInputSpace =       wf.outputLandmarksInInputSpace.lzout.out 
#    bcd.inputs.outputResampledVolume =             wf.outputResampledVolume.lzout.out 
#    bcd.inputs.outputTransform =                   wf.outputTransform.lzout.out 
#    bcd.inputs.outputLandmarksInACPCAlignedSpace = "test.fcsv"            #wf.outputLandmarksInACPCAlignedSpace.lzout.out 
#    bcd.inputs.writeBranded2DImage =               "test.png"            #wf.writeBranded2DImage.lzout.out 
#    wf.add(bcd)
#
#    # Set the filename of the output of Resample
#    wf.add(append_filename(name="resampledOutputVolume", filename=wf.source_node.lzout.t1, append_str="_resampled", extension=".nii.gz"))
# 
#    # Set the inputs of Resample
##    resample = BRAINSResample("BRAINSResample").get_task()
##    resample.inputs.inputVolume =       wf.BRAINSConstellationDetector.lzout.outputResampledVolume
##    resample.inputs.interpolationMode = "Linear"
##    resample.inputs.pixelType =         "binary"
##    resample.inputs.referenceVolume =   "/localscratch/Users/cjohnson30/resample_refs/t1_average_BRAINSABC.nii.gz" 
##    resample.inputs.warpTransform =     "/localscratch/Users/cjohnson30/resample_refs/atlas_to_subject.h5" # outputTransform
##    resample.inputs.outputVolume =      wf.resampledOutputVolume.lzout.out 
##    wf.add(resample)
#
#    # Copy the files from the cache to the output directory so the resulting files can be accessed
##    wf.add(copy_from_cache(name="outputLandmarksInInputSpaceWritten",       cache_path=wf.BRAINSConstellationDetector.lzout.outputLandmarksInInputSpace,       output_dir=output_dir))
##    wf.add(copy_from_cache(name="outputResampledVolumeWritten",             cache_path=wf.BRAINSConstellationDetector.lzout.outputResampledVolume,             output_dir=output_dir))
##    wf.add(copy_from_cache(name="outputTransformWritten",                   cache_path=wf.BRAINSConstellationDetector.lzout.outputTransform,                   output_dir=output_dir))
##    wf.add(copy_from_cache(name="outputLandmarksInACPCAlignedSpaceWritten", cache_path=wf.BRAINSConstellationDetector.lzout.outputLandmarksInACPCAlignedSpace, output_dir=output_dir))
##    wf.add(copy_from_cache(name="writeBranded2DImageWritten",               cache_path=wf.BRAINSConstellationDetector.lzout.writeBranded2DImage,               output_dir=output_dir))
##    wf.add(copy_from_cache(name="outputVolumeWritten",                      cache_path=wf.BRAINSResample.lzout.outputVolume,                                   output_dir=output_dir))
# 
#    # Set the outputs of the entire workflow
    wf.set_output(
        [
            ("outputLandmarksInInputSpace",       wf.outputLandmarksInInputSpace.lzout.out),
#            ("outputLandmarksInInputSpace",       wf.BRAINSConstellationDetector.lzout.outputLandmarksInInputSpace),
#            ("outputResampledVolume",             wf.BRAINSConstellationDetector.lzout.outputResampledVolume),
#            ("outputTransform",                   wf.BRAINSConstellationDetector.lzout.outputTransform),
#            ("outputLandmarksInACPCAlignedSpace", wf.BRAINSConstellationDetector.lzout.outputLandmarksInACPCAlignedSpace),
#            ("writeBranded2DImage",               wf.BRAINSConstellationDetector.lzout.writeBranded2DImage),
#            ("resampledOutputVolume",             wf.BRAINSResample.lzout.outputVolume),
        ]
    )

    source_node.add(wf)
    source_node.set_output([("out", source_node.wf.lzout.outputLandmarksInInputSpace)])
   
    t0 = time.time() 
    # Run the pipeline
    with pydra.Submitter(plugin="cf") as sub:
        sub(source_node)
    result = source_node.result()
    print(result)
    print(f"total time: {time.time() - t0}")
